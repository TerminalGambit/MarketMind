{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a33c832f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T17:07:59.555620Z",
     "iopub.status.busy": "2025-12-14T17:07:59.555476Z",
     "iopub.status.idle": "2025-12-14T17:07:59.558886Z",
     "shell.execute_reply": "2025-12-14T17:07:59.558150Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---\n",
    "# title: Data Engineering Foundations\n",
    "# tags: [DataEngineering, MedallionArch, Parquet, Scraping]\n",
    "# difficulty: Beginner\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d40abb",
   "metadata": {},
   "source": [
    "# Data Engineering Foundations: The Medallion Architecture\n",
    "\n",
    "Welcome to the **Market-Mind Library**. In this first module, we explore how to build a robust financial data lake.\n",
    "\n",
    "## Concepts Covered\n",
    "1.  **Medallion Architecture**: Why we split data into Bronze (Raw), Silver (Clean), and Gold (Business-Level).\n",
    "2.  **Parquet vs CSV**: Why Parquet is superior for time-series data (columnar storage, type retention).\n",
    "3.  **ETL Pipelines**: Extracting from APIs (yfinance) and Web (Selenium).\n",
    "\n",
    "### 1. The Architecture\n",
    "We organize our data directory like this:\n",
    "- `data/bronze`: Immutable raw dumps. If code breaks, we delete Silver/Gold and re-run from here.\n",
    "- `data/silver`: Enriched data. Dates aligned, missing values filled, types cast.\n",
    "- `data/gold`: Aggregated data ready for ML/Analytics.\n",
    "\n",
    "Let's inspect our current setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a714db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T17:07:59.560811Z",
     "iopub.status.busy": "2025-12-14T17:07:59.560668Z",
     "iopub.status.idle": "2025-12-14T17:07:59.852427Z",
     "shell.execute_reply": "2025-12-14T17:07:59.851975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRONZE Layer: 3 files\n",
      "SILVER Layer: 5 files\n",
      "GOLD Layer: 3 files\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(\"../data\")\n",
    "for layer in ['bronze', 'silver', 'gold']:\n",
    "    path = base_path / layer\n",
    "    count = len(list(path.glob(\"*\")))\n",
    "    print(f\"{layer.upper()} Layer: {count} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d578f",
   "metadata": {},
   "source": [
    "### 2. Efficiency: Parquet vs CSV\n",
    "Let's start the `MarketDataFetcher` manually and compare formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac35bff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T17:07:59.853643Z",
     "iopub.status.busy": "2025-12-14T17:07:59.853527Z",
     "iopub.status.idle": "2025-12-14T17:08:00.355932Z",
     "shell.execute_reply": "2025-12-14T17:08:00.355441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 1 tickers: ['AAPL'] over 5d...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw data to market_mind/data/bronze/market_data_5d_20251214_180800.parquet\n",
      "Ticker            AAPL                                              \n",
      "Price             Open        High         Low       Close    Volume\n",
      "Date                                                                \n",
      "2025-12-08  278.130005  279.670013  276.149994  277.890015  38211800\n",
      "2025-12-09  278.160004  280.029999  276.920013  277.179993  32193300\n",
      "2025-12-10  277.750000  279.750000  276.440002  278.779999  33038300\n",
      "2025-12-11  279.100006  279.589996  273.809998  278.029999  33248000\n",
      "2025-12-12  277.795013  279.220001  276.820007  278.279999  38360082\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from ingestion.market_data import MarketDataFetcher\n",
    "\n",
    "# Fetch a small sample\n",
    "fetcher = MarketDataFetcher()\n",
    "df = fetcher.fetch_history([\"AAPL\"], period=\"5d\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d7ba8",
   "metadata": {},
   "source": [
    "### 3. Web Scraping with Selenium\n",
    "Scraping is fragile. We use `try/except` blocks and fallback mechanisms (like our Mock Data generator) to ensure pipeline stability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
